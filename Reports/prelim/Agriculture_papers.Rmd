---
title: "Peatland Searches"
author: "Matt"
date: "26 5 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load libraries
library(PRISMAstatement)
library(tidyverse)
library(bibliometrix)
library(litsearchr)
library(revtools)
```


## Agriculture Group

### Web of Science search:

((((peat  OR peatland  OR peatlands  OR bog  OR fen  OR mire)  NOT  ((tropic* NEAR/3 peat*)  OR  (tropic* NEAR/3 fen*)  OR  subtropic*  OR  malays*  OR  indones*  OR  india*  OR  amason*  OR  amazon*  OR  brazil*  OR  congo*)))  AND ((peat* NEAR/5 (agricultur* OR cultivated OR arable)) OR (drain* NEAR/5 agricultur*)))

### WoS Search parameters

Web of Science Core Collection: Citation Indexes
Science Citation Index Expanded (SCI-EXPANDED) --1987-present
Social Sciences Citation Index (SSCI) --1987-present
Arts & Humanities Citation Index (A&HCI) --1987-present
Emerging Sources Citation Index (ESCI) --2015-present

### Prisma statement

> TBC 

```{r prisma}
prisma(found = 617,
       found_other = 0,
       no_dupes = 0, 
       screened = 0, 
       screen_exclusions = 0, 
       full_text = 0,
       full_text_exclusions = 0, 
       qualitative = 0, 
       quantitative = 0,
       width = 200, height = 200)
```

## BibliometrixR 
### Read in bib files

```{r read in files and combine}

filelist=list.files(paste0(here::here(),"/data"), pattern="^.*Agriculture.*.bib") 

M <- convert2df(file = c(paste0(here::here(),"/data/",filelist[1]), paste0(here::here(),"/data/",filelist[2])), dbsource = "wos", format = "bibtex")

```

```{r check that M contains all files}
dim(M)[1]==617

```


### Summary of the corpus

```{r look at biblio summary}
results <- biblioAnalysis(M, sep = ";")
S <- summary(object = results, k = 40, pause = FALSE)


```

### Most cited papers in the corpus

```{r}
kableExtra::kable(S$MostCitedPapers) %>% kableExtra::kable_styling() %>% kableExtra::scroll_box()
```


### Most cited references in the corpus

```{r most cited references}
CR <- citations(M, field = "article", sep = ";")
kableExtra::kable(cbind(CR$Cited[1:30])) %>% kableExtra::kable_styling()%>% kableExtra::scroll_box()
```

### Keyword co-occurrence network - shared keywords between publications

```{r}
# Create keyword co-occurrences network
NetMatrix <- biblioNetwork(M, analysis = "co-occurrences", network = "keywords", sep = ";")

# full network
net=networkPlot(NetMatrix, normalize="association", weighted=T, n = 617, Title = "Keyword Co-occurrences", type = "fruchterman", size=T,edgesize = 5,label= FALSE)
```


```{r}
#get the cluster for each paper
# net$cluster_res
# net$community_obj$memberships
mat=as.data.frame(t(net$community_obj$memberships))

membership=data.frame("Authors"=M$AU, "Title"=M$TI, "Year"=M$PY, "cluster"=mat$V2)
kableExtra::kable(membership) %>% kableExtra::kable_styling() %>% kableExtra::scroll_box()
```
```{r, results='hide'}
#clusternames
net$cluster_res %>% 
  group_by(cluster) %>%
  mutate(ismax=if_else(btw_centrality==max(btw_centrality), "Yes","No")) %>% 
  filter(ismax=="Yes") %>% 
  select(vertex)->cluster_names
  

cluster_names=cluster_names[c(1:7,18:21 ),]



```

### Trend in clusters over time 

```{r}
membership=membership %>% 
  inner_join(cluster_names)

pal=RColorBrewer::brewer.pal(dim(cluster_names)[1],name ="Paired" )
  
membership %>% 
  group_by(vertex) %>% 
  ggplot(aes(Year)) +
  geom_histogram(fill="darkred")+
  theme_classic()+
  facet_wrap(~vertex)
```

## Co-Citation network (where papers cite each other)

```{r}
NetMatrix <- biblioNetwork(M, analysis = "co-citation", network = "references", sep = ";")
net <- networkPlot(NetMatrix, n =100, type = "kamada", Title = "Co-Citation",label=FALSE)

```

## Bibliometrix coupling (where paper A and paper B both cite paper C they are said to be coupled)

```{r}

NetMatrix <- biblioNetwork(M, analysis = "coupling", network = "references", sep = ".  ")
net=networkPlot(NetMatrix,  normalize = "salton", weighted=NULL, n = 100, Title = "Coupling", type = "fruchterman", size=8,size.cex=T,remove.multiple=TRUE,labelsize=0.4,label=FALSE,label.cex=F)
```

We can identify each publication in each coupled cluster

## Thematic evolution of the corpus

```{r}
years=c(1995,2000, 2010, 2015)

nexus <- thematicEvolution(M,field="ID",years=years,n=100,minFreq=2)
plotThematicEvolution(nexus$Nodes,nexus$Edges)

```

## Thematic Map - identifies themes that are central to the corpus, those that are limited within the corpus and those either increasing or decreasing in importance (the opposite effects are not identifed in this analysis)

```{r}
tm=thematicMap(
M,
field = "ID",
n = 250,
minfreq = 5,
ngrams = 1,
stemming = FALSE,
size = 0.5,
n.labels = 1,
repel = TRUE
)
tm$map
```

# LitSearchR - find additional keywords

```{r}
#search_directory <- list.files(paste0(here::here(),"/data"), pattern="^.*Agriculture.*.txt", full.names = TRUE)


naiveimport <-
  litsearchr::import_results(directory =paste0(here::here(),"/data/txt.files"), verbose = TRUE)

naiveresults <-
  litsearchr::remove_duplicates(naiveimport, field = "title", method = "string_osa")# not needed here but leaving it in as it might be in future

```

```{r}
rakedkeywords <-
  litsearchr::extract_terms(
    text = paste(naiveresults$title, naiveresults$abstract),
    method = "fakerake",
    min_freq = 2,
    ngrams = TRUE,
    min_n = 2,
    language = "English"
  )
#> Loading required namespace: stopwords

taggedkeywords <-
  litsearchr::extract_terms(
    keywords = naiveresults$keywords,
    method = "tagged",
    min_freq = 2,
    ngrams = TRUE,
    min_n = 2,
    language = "English"
  )

```
```{r}
all_keywords <- unique(append(taggedkeywords, rakedkeywords))

naivedfm <-
  litsearchr::create_dfm(
    elements = paste(naiveresults$title, naiveresults$abstract),
    features = all_keywords
  )

naivegraph <-
  litsearchr::create_network(
    search_dfm = naivedfm,
    min_studies = 2,
    min_occ = 2
  )


```


```{r}
cutoff <-
  litsearchr::find_cutoff(
    naivegraph,
    method = "cumulative",
    percent = .80,
    imp_method = "strength"
  )

reducedgraph <-
  litsearchr::reduce_graph(naivegraph, cutoff_strength = cutoff[1])

searchterms <- litsearchr::get_keywords(reducedgraph)

kableExtra::kable(searchterms) %>% kableExtra::kable_styling()%>% kableExtra::scroll_box()
```

# Topic modelling of Title, keywords and abstracts 

```{r}
#data_all <-revtools::read_bibliography(c(paste0(here::here(),"/data/",filelist[1]), paste0(here::here(),"/data/",filelist[2])))
```


```{r}
#topics<-screen_topics(data_all)
#saveRDS(topics, "data/topics.rds")
```

```{r}
topics <- readRDS("C:/Users/matthew.grainger/Documents/Projects_in_development/PeatReview/Reports/data/topics.rds")
#result <-ldatuning::FindTopicsNumber(
#  topics$dtm,
#  topics = seq(from = 25, to = 40, by = 1),
#  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
#  method = "Gibbs",
#  control = list(seed = 77),
#  mc.cores = 2L,
#  verbose = TRUE
#)
#saveRDS(result, "data/result.rds")
result <- readRDS("C:/Users/matthew.grainger/Documents/Projects_in_development/PeatReview/Reports/data/result.rds")
ldatuning::FindTopicsNumber_plot(result)

```

The number of groups supported by the model is 38 

```{r}
tms=topicmodels::LDA(topics$dtm,k=38)
```


```{r}
tmResult <- topicmodels::posterior(tms)
beta <- tmResult$terms   # get beta from results
theta <- tmResult$topics 
```


```{r}
tms_10=topicmodels::terms(tms, 10)
kableExtra::kable(tms_10) %>% kableExtra::kable_styling()%>% kableExtra::scroll_box()
```

```{r}

topicNames <- apply(lda::top.topic.words(beta, 5, by.score = T), 2, paste, collapse = " ")
```

```{r}
countsOfPrimaryTopics <- rep(0, 38)
names(countsOfPrimaryTopics) <- topicNames
for (i in 1:617) {
  topicsPerDoc <- theta[i, ] # select topic distribution for document i
  # get first element position from ordered list
  primaryTopic <- order(topicsPerDoc, decreasing = TRUE)[1] 
  countsOfPrimaryTopics[primaryTopic] <- countsOfPrimaryTopics[primaryTopic] + 1
}
kableExtra::kable(sort(countsOfPrimaryTopics, decreasing = TRUE)) %>% kableExtra::kable_styling()%>% kableExtra::scroll_box()
```



